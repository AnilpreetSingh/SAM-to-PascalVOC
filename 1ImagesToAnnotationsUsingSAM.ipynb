{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpaRfw4YlBsT"
   },
   "source": [
    "# Libraries and SAM initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXjy9vTGrfsf",
    "outputId": "d507570e-d95a-4226-fc31-4e15fd4fd927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2+cu121\n",
      "Torchvision version: 0.17.2+cu121\n",
      "CUDA is available: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "import sys\n",
    "# !{sys.executable} -m pip install opencv-python matplotlib\n",
    "# !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "\n",
    "\n",
    "# !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
    "# !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "98lYl97_rhQ1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.cluster import KMeans\n",
    "import copy\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "s9TEr2wirmOb"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "# sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
    "model_type = \"vit_b\"\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fU18cQ0cIzqu"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LcVR7UPlk_Kq"
   },
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pkpI6kOurnpF"
   },
   "outputs": [],
   "source": [
    "def returnMasks(image):\n",
    "    mask_generator_2 = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=160,\n",
    "    pred_iou_thresh=0.85,\n",
    "    stability_score_thresh=0.85,\n",
    "    # crop_n_layers=2,\n",
    "    # crop_n_points_downscale_factor=3,\n",
    "    min_mask_region_area=100,\n",
    "    stability_score_offset = 1.0,\n",
    "    box_nms_thresh = 0.7,\n",
    "    # crop_nms_thresh = 0.7,\n",
    "    )\n",
    "    masks = mask_generator_2.generate(image)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hSXXr6V9TqnV"
   },
   "outputs": [],
   "source": [
    "def findcolors(image):\n",
    "    # Define color ranges for pink, white, purple, and black\n",
    "    pink_lower = np.array([150, 50, 150], dtype=np.uint8)\n",
    "    pink_upper = np.array([255, 150, 255], dtype=np.uint8)\n",
    "\n",
    "    white_lower = np.array([200, 200, 200], dtype=np.uint8)\n",
    "    white_upper = np.array([255, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    purple_lower = np.array([100, 0, 100], dtype=np.uint8)\n",
    "    purple_upper = np.array([180, 100, 180], dtype=np.uint8)\n",
    "\n",
    "    black_lower = np.array([0, 0, 0], dtype=np.uint8)\n",
    "    black_upper = np.array([30, 30, 30], dtype=np.uint8)\n",
    "\n",
    "    # Create masks for each color range\n",
    "    pink_mask = cv2.inRange(image, pink_lower, pink_upper)\n",
    "    white_mask = cv2.inRange(image, white_lower, white_upper)\n",
    "    purple_mask = cv2.inRange(image, purple_lower, purple_upper)\n",
    "    black_mask = cv2.inRange(image, black_lower, black_upper)\n",
    "\n",
    "    # Calculate the number of pixels for each color\n",
    "    np_pixels = np.sum(pink_mask > 0)\n",
    "    nw_pixels = np.sum(white_mask > 0)\n",
    "    npr_pixels = np.sum(purple_mask > 0)\n",
    "\n",
    "    # Calculate percentages\n",
    "    total_pixels = np_pixels+nw_pixels+npr_pixels  # Total number of pixels (assuming 3 channels)\n",
    "    np_percentage = (np_pixels / total_pixels) * 100\n",
    "    nw_percentage = (nw_pixels / total_pixels) * 100\n",
    "    npr_percentage = (npr_pixels / total_pixels) * 100\n",
    "\n",
    "    # Format the result as a string\n",
    "    result_string = f\"Pink: {np_percentage:.2f}%, White: {nw_percentage:.2f}%, Purple: {npr_percentage:.2f}%\"\n",
    "\n",
    "    return [np_percentage,nw_percentage,npr_percentage],result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rJaMztV_G98s"
   },
   "outputs": [],
   "source": [
    "def pltshow(image,title='',annotations=False,size=5):\n",
    "    plt.figure(figsize=(size,size))\n",
    "    plt.imshow(image)\n",
    "    if(annotations):\n",
    "        show_anns(masks)\n",
    "    plt.axis('off')\n",
    "    if(title!=''):\n",
    "        plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0sDO19J1nNl8"
   },
   "outputs": [],
   "source": [
    "def remove_directory(directory_path):\n",
    "    try:\n",
    "        shutil.rmtree(directory_path)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MWDZXCCP9Ygg"
   },
   "outputs": [],
   "source": [
    "def binarize(rgb_image):\n",
    "\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the grayscale image to create a binary mask\n",
    "    _, binary_mask = cv2.threshold(gray_image, 1, 255, cv2.THRESH_BINARY)\n",
    "    return binary_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "axwgP4OY9Ppt"
   },
   "outputs": [],
   "source": [
    "def find_circularity(input_image):\n",
    "  # mask = cv2.imread('1000masks/100.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "  mask=cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "  # mask=cv2.GaussianBlur(mask,(3,3),0)\n",
    "  _, binary_mask = cv2.threshold(mask, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "  # Find contours in the mask\n",
    "  contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # Convert the mask to BGR for visualization\n",
    "  color_mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "  net_cicularity=[]\n",
    "  for contour in contours:\n",
    "      # Calculate area and perimeter of the contour\n",
    "      area = cv2.contourArea(contour)\n",
    "      perimeter = cv2.arcLength(contour, True)\n",
    "      if area==0 or perimeter==0:\n",
    "        circularity=0\n",
    "        continue\n",
    "      # Calculate circularity using the formula\n",
    "      circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "\n",
    "      # Draw the contour on the color_mask image\n",
    "      cv2.drawContours(color_mask, [contour], -1, (0, 255, 0), 2)  # Green color, thickness=2\n",
    "\n",
    "      # Display circularity value on the image\n",
    "      cv2.putText(color_mask, f\"{circularity:.2f}\", tuple(contour[0][0]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "      # title+=str(f\"{circularity:.2f} \")\n",
    "      net_cicularity.append(circularity)\n",
    "  if len(net_cicularity)==0:\n",
    "      return 0\n",
    "  avg_circularity=sum(net_cicularity) / len(net_cicularity)\n",
    "  return  color_mask,avg_circularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lQWIR9K4yTkb"
   },
   "outputs": [],
   "source": [
    "def findVariance(image):\n",
    "    _, stds = cv2.meanStdDev(image)\n",
    "    return stds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DwMT9EhmyWQm"
   },
   "outputs": [],
   "source": [
    "#Simple function to calc color vectors and circularity:\n",
    "def find_features_color_circularity_variance(image):\n",
    "  colorVector,_=findcolors(image)\n",
    "  _,circularity=find_circularity(image)\n",
    "  variance=findVariance(image)\n",
    "\n",
    "  for i,val in enumerate(colorVector):\n",
    "        if np.isnan(val):\n",
    "            colorVector[i]==0.0\n",
    "  if np.isnan(circularity):\n",
    "        circularity=0.0\n",
    "  for i,val in enumerate(variance):\n",
    "        if np.isnan(val):\n",
    "            variance[i]==0.0\n",
    "  return np.concatenate((colorVector, [circularity*colorVector[1]], variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KAklMbDsF_i-"
   },
   "outputs": [],
   "source": [
    "def showClassDiffnew(inp_all_masks,inp_labels,inp_classes):\n",
    "  all_masks_array = np.array(inp_all_masks)\n",
    "  labels_array = np.array(inp_labels)\n",
    "\n",
    "  random_indices = np.random.permutation(len(inp_all_masks))\n",
    "  all_masks_array = all_masks_array[random_indices]\n",
    "  labels_array = labels_array[random_indices]\n",
    "\n",
    "  # Set up the figure with subplots\n",
    "  fig, axs = plt.subplots(len(inp_classes), 10, figsize=(25, 10))\n",
    "\n",
    "  # Iterate over each class\n",
    "  for i, class_label in enumerate(inp_classes):\n",
    "      # Select 10 images for the current class\n",
    "      class_images = all_masks_array[labels_array == class_label][:10]\n",
    "      # Display each image in the corresponding subplot\n",
    "      for j in range(10):\n",
    "          axs[i, j].imshow(cv2.imread(masks_directory+'/'+class_images[j]))\n",
    "          axs[i, j].axis('off')\n",
    "\n",
    "          # # Add title with the class label\n",
    "          axs[i, j].set_title(f'Class {class_label}')\n",
    "\n",
    "  # Adjust layout to prevent clipping of titles\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tp8tsZYbCBY3"
   },
   "outputs": [],
   "source": [
    "def remove_white_and_bone(original,remove):\n",
    "    white_lower = np.array([170, 170, 170], dtype=np.uint8)\n",
    "    white_upper = np.array([255, 255, 255], dtype=np.uint8)\n",
    "    white_mask = cv2.inRange(original, white_lower, white_upper)\n",
    "\n",
    "    inv_white_mask = cv2.bitwise_not(white_mask)\n",
    "    inv_remove = cv2.bitwise_not(remove)\n",
    "    inv_white_mask_minus_bone = cv2.bitwise_and(inv_white_mask, inv_white_mask, mask=inv_remove)\n",
    "\n",
    "    return inv_white_mask_minus_bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "fcFSXgGXr9tl",
    "outputId": "f4da1b82-fb34-4563-f31b-004d1f5243dc"
   },
   "outputs": [],
   "source": [
    "# for imagepath in os.readfile('./content/input'):\n",
    "imagepath='cellu.jpg'\n",
    "image=cv2.imread(imagepath)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "pltshow(image,size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_NiLLirwaP6",
    "outputId": "148e65b0-1adb-41c7-f560-da8633d6103b"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "masks=returnMasks(image)\n",
    "len(masks)\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "_Rr4S91o51Yr",
    "outputId": "b055b34b-942f-442c-ea13-12cec48b7f3f"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pltshow(image,annotations=True,size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "68w9VomcHonm",
    "outputId": "1e6d0349-25f3-4311-f5aa-f196adc4eb21"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for mask in masks:\n",
    "        mask_image = (mask['segmentation'] * 255).astype(np.uint8)\n",
    "        result_image = cv2.bitwise_and(image, image, mask=mask_image)\n",
    "        pltshow(result_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImlPH3bf3pxi"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "totalColorvec=[]\n",
    "for mask in masks:\n",
    "    mask_image = (mask['segmentation'] * 255).astype(np.uint8)\n",
    "    result_image = cv2.bitwise_and(image, image, mask=mask_image)\n",
    "    colorvec,title=findcolors(result_image)\n",
    "    totalColorvec.append(colorvec)\n",
    "    # pltshow(result_image,title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "neVTuJPLgCZ4"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Kmean\n",
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 3\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "labels = kmeans.fit_predict(totalColorvec)\n",
    "print(\"Cluster Labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_mb2zawglLC"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for i,mask in enumerate(masks):\n",
    "    mask_image = (mask['segmentation'] * 255).astype(np.uint8)\n",
    "    result_image = cv2.bitwise_and(image, image, mask=mask_image)\n",
    "    pltshow(result_image,title=labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8AnVvhL9fLD"
   },
   "source": [
    " **try 2, k means of the color features of all the masks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbagMwjpz7RS"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "input_directory_path='/content/drive/MyDrive/ImagesData'\n",
    "output_directory_path='/content/1000masks'\n",
    "!mkdir $output_directory_path\n",
    "allmasks=[]\n",
    "allmaskfeatures=[]\n",
    "i=0\n",
    "for imagefile in os.listdir(input_directory_path):\n",
    "    if imagefile=='.ipynb_checkpoints':\n",
    "        continue\n",
    "    image_path=os.path.join(input_directory_path, imagefile)\n",
    "\n",
    "    image=cv2.imread(image_path)\n",
    "\n",
    "    masks=returnMasks(image)\n",
    "    print(i)\n",
    "    for mask in masks:\n",
    "        mask_image = (mask['segmentation'] * 255).astype(np.uint8)\n",
    "        result_image = cv2.bitwise_and(image, image, mask=mask_image)\n",
    "        allmasks.append(result_image)\n",
    "        colorvec=findcolors(result_image)\n",
    "        allmaskfeatures.append(colorvec)\n",
    "        i+=1\n",
    "\n",
    "labels=kmeans(totalColorvec,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bewtfnVU9arw"
   },
   "source": [
    "**try 3, Kmeans, heirarichal agglomerative clustering, DBSCAN on direct masks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhV-02-XZFWl"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "input_directory_path='/content/drive/MyDrive/ImagesData'\n",
    "output_directory_path='/content/1000masks'\n",
    "!mkdir $output_directory_path\n",
    "allmasks=[]\n",
    "i=0\n",
    "for imagefile in os.listdir(input_directory_path):\n",
    "    if imagefile=='.ipynb_checkpoints':\n",
    "        continue\n",
    "    image_path=os.path.join(input_directory_path, imagefile)\n",
    "\n",
    "    image=cv2.imread(image_path)\n",
    "\n",
    "    masks=returnMasks(image)\n",
    "    print(i)\n",
    "    for mask in masks:\n",
    "        mask_image = (mask['segmentation'] * 255).astype(np.uint8)\n",
    "        result_image = cv2.bitwise_and(image, image, mask=mask_image)\n",
    "        cv2.imwrite(output_directory_path+'/'+str(i)+'.jpg',result_image)\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKvTs03An_zu"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "def load_images_from_directory(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.png', '.jpeg')):  # Add more extensions if needed\n",
    "            path = os.path.join(directory, filename)\n",
    "            image = cv2.imread(path)  # Load images in grayscale\n",
    "            images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "# Replace 'your_directory_path' with the actual path to your image directory\n",
    "image_directory = '/content/1000masks'\n",
    "X = load_images_from_directory(image_directory)\n",
    "X_flatten = X.reshape((len(X), -1, 3))  # Assuming 3 channels (RGB)\n",
    "\n",
    "# Apply Hierarchical Clustering\n",
    "n_clusters = 3\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "agg_labels = agg_clustering.fit_predict(X_flatten.reshape((len(X_flatten), -1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7zzI0GAtEs8",
    "outputId": "7c9c45b5-e8ce-42a5-976c-4f508c308edd"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# # fig, axs = plt.subplots(n_clusters, 10, figsize=(15, 6))\n",
    "num0,num1,num2=0,0,0\n",
    "\n",
    "for i in agg_labels:\n",
    "  if i ==0:\n",
    "    num0+=1\n",
    "  elif i ==1:\n",
    "    num1+=1\n",
    "  elif i ==2:\n",
    "    num2+=1\n",
    "print(num0,num1,num2)\n",
    "#overpowered 1 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1t-rgjT49rVH",
    "outputId": "f87c0a44-9f95-4f1b-f57f-4e520be1e88c"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "dbscan = DBSCAN(eps=3, min_samples=500)  # Adjust eps and min_samples based on your data\n",
    "dbscan_labels = dbscan.fit_predict(X_flatten.reshape((len(X_flatten), -1)))\n",
    "print(np.unique(dbscan_labels))\n",
    "# Get indices of images in each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90CzZ7cx98X4"
   },
   "source": [
    "**Try 4, improving feature vector of masks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VY2TrTxJ-LY6"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "all_masks=[]\n",
    "for mask_name in os.listdir('/content/1000masks'):\n",
    "  mask_path='/content/1000masks/'+mask_name\n",
    "  mask=cv2.imread(mask_path)\n",
    "  all_masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v63RGb-pAY_i"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#1st feature vector= the 3 colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xpc5ZD2aAfVr",
    "outputId": "bda1f833-4d30-4421-aeea-41d71d62161d"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "features_3colors=[]\n",
    "for mask in all_masks:\n",
    "  features,title=findcolors(mask)\n",
    "  features_3colors.append(features)\n",
    "labels3clr=kmeans(features_3colors,3)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Total time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "Rt7U3wJjk84r",
    "outputId": "37947506-624b-476a-8fca-44ada147b6b1"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "showClassDiff(all_masks,labels3clr,[0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kntctr8kFQi"
   },
   "source": [
    "**2nd feature vector pink,purple,white, circularity*white**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gS31_pjePHJt",
    "outputId": "be83eec4-8efd-4a1e-ad24-bd74fac62b13"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for mask in all_masks[:20]:\n",
    "  mask,circularity=find_circularity(mask)\n",
    "  pltshow(mask,title=str(f\"{circularity:.2f} \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaH4ABv4pUDL",
    "outputId": "b9bfd6dc-430d-4eaf-f10c-f941bda8ad1a"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'segdiff' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n segdiff ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "features_3colors_circularity=[]\n",
    "for mask in all_masks:\n",
    "  features_3colors_circularity.append(find_features_color_circularity(mask))\n",
    "\n",
    "labelscolorCircularity=kmeans(features_3colors_circularity,4)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Total time: {elapsed_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "NLRk6O2cqIaD",
    "outputId": "fde2e4c7-bd51-44ba-c0eb-ae2d5355e309"
   },
   "outputs": [],
   "source": [
    "showClassDiff(all_masks,labelscolorCircularity,[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "qRQ2XsM8tME-",
    "outputId": "43effed3-df87-41d9-f112-1aa028af95c8"
   },
   "outputs": [],
   "source": [
    "#performig DBSCAN on 4features\n",
    "dbscan = DBSCAN(eps=20, min_samples=500)  # Adjust eps and min_samples based on your data\n",
    "dbscan_labels = dbscan.fit_predict(features_3colors_circularity)\n",
    "showClassDiff(all_masks,dbscan_labels,[-1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "KIcS7H4WuaQd",
    "outputId": "45dcdc7b-8cb9-4afd-874c-3b5e57e71dd4"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "agglomerative_clustering = AgglomerativeClustering(n_clusters=4)\n",
    "heir_cluster_labels = agglomerative_clustering.fit_predict(features_3colors_circularity)\n",
    "\n",
    "# Plot the dendrogram (optional)\n",
    "linkage_matrix = linkage(features_3colors_circularity, method='ward')\n",
    "dendrogram(linkage_matrix)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "V7dv2mvounJ5",
    "outputId": "d2782bf9-c654-4f4e-b9f7-08881db71a45"
   },
   "outputs": [],
   "source": [
    "showClassDiff(all_masks,heir_cluster_labels,[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D03_T9jp1dzX"
   },
   "outputs": [],
   "source": [
    "svmModel=joblib.load(\"./svm_color_circu_stds_91.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITc3BjCxSAsq"
   },
   "outputs": [],
   "source": [
    "imageBG=cv2.imread(\"./Individual-Masks-PGI-clean/PGI_image_0/bg/1.jpg\")\n",
    "imageCell=cv2.imread(\"./Individual-Masks-PGI-clean/PGI_image_0/cell/0.jpg\")\n",
    "imageBone=cv2.imread(\"./Individual-Masks-PGI-clean/PGI_image_1/bone/36.jpg\")\n",
    "imageFat=cv2.imread(\"./Individual-Masks-PGI-clean/PGI_image_0/fat/7.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJsypUCGRMca",
    "outputId": "110f29d8-c8d8-4c17-82da-d23574e31f26"
   },
   "outputs": [],
   "source": [
    "featureTesting=find_features_color_circularity_variance(imageBG)\n",
    "svmModel.predict([featureTesting])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM52mqQIk1Uj"
   },
   "source": [
    "# Dataset making part 1 (from images to classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM52mqQIk1Uj"
   },
   "source": [
    " Once we have images that we would like to automatically Annotate, we can use SAM to segment large and distinct areas of the images, these \"segmentation objects\" are delivered as binary masks. Each segmentation object/binary mask is representation of the region that SAM seperated. These segmentation objects are unclassified, so for actual segmentation we need to provide some class to them. Therefore we initially classified masks manually then used that data to train an SVM model that classifies masks based upon their features.  Let's first look at how SAM is converting images to segmentation objects and also saving their \"feature vector\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDc_ykZFlpg3"
   },
   "outputs": [],
   "source": [
    "input_directory_path='images126' #input direcory contating images\n",
    "output_directory_path='./output126' #output directory that will contain classified segmentations\n",
    "masks_directory='pgi126' # a folder to contain all masks generated by all images for classification together\n",
    "!mkdir  $output_directory_path $masks_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "Ue_wkJtn9pbx",
    "outputId": "01a3c5ac-5f6f-4a45-c2f2-53814bae3bec"
   },
   "outputs": [],
   "source": [
    "featureVec=[] #saving features of each mask sequentially\n",
    "masksPerImage=[] # a list of number of masks per image\n",
    "mask_names=[] # names of each mask saved sequentially \n",
    "n_mask=0 #total number of masks\n",
    "\n",
    "for n,imagefile in enumerate(os.listdir(input_directory_path)):\n",
    "    print(n,end='-')\n",
    "    image_name='PGI_image_'+str(n) # Naming the images using our nomenclature i.e. PGI_imaage_0,PGI_imaage_1.....\n",
    "    image_path=os.path.join(input_directory_path,imagefile)\n",
    "\n",
    "\n",
    "    # Our annotations will first be saved in a folder containing all image's annotations. the structureof this folder will be:\n",
    "    #PGI_image_0\n",
    "     #-->og.tif\n",
    "     #-->bone\n",
    "     #   |-->0.jpg\n",
    "     #   |-->3.jpg\n",
    "     #\n",
    "     #-->bg\n",
    "     #   |-->2.jpg\n",
    "     #\n",
    "     #-->fat\n",
    "     #   |-->1.jpg\n",
    "     #\n",
    "     #-->cell\n",
    "     #   |-->4.jpg\n",
    "     #   |-->5.jpg\n",
    "    output_dir=output_directory_path+'/'+image_name # The path and name of a new directory that will save this image's annotations\n",
    "    remove_directory(output_dir) # removing the directory and its contents if it already exists\n",
    "\n",
    "    os.mkdir(output_dir)\n",
    "    os.mkdir(output_dir+'/bone') \n",
    "    os.mkdir(output_dir+'/bg')\n",
    "    os.mkdir(output_dir+'/fat')\n",
    "    os.mkdir(output_dir+'/cell')\n",
    "\n",
    "    image=cv2.imread(image_path)\n",
    "    cv2.imwrite(output_dir+'/og.tif',image) #Saving the original image as well in the folder, normally tif or jpg\n",
    "\n",
    "    masks=returnMasks(image) # generating masks using SAM, the output is a list of binary image with white region as the segmented area/foreground and black being the rest of the image/background\n",
    "    masksPerImage.append(len(masks))\n",
    "\n",
    "    for mask in masks: # reading individual binary image\n",
    "        mask_image = (mask['segmentation'] * 255).astype(np.uint8) # mask['segmentation'] contatins the acutal mask, which needs to be converted from 0,1 to 0,255 and then to uint8\n",
    "        result_image = cv2.bitwise_and(image, image, mask=mask_image) # converting binary mask to a cutout of the original image, result_image is like the original image but with the parts that were background in segmentation object being black in this image too\n",
    "        featureVec.append( find_features_color_circularity_variance(result_image) ) # finding the feature vector of the result_image, more explanation about featurevector in its respective function defination\n",
    "        cv2.imwrite(masks_directory+'/'+image_name+'-'+str(n_mask)+'.jpg',result_image) #saving the mask as PGI_image_0-0.jpg\n",
    "        mask_names.append(image_name+'-'+str(n_mask)+'.jpg') # appending mask name 0.jpg to mask_names\n",
    "        n_mask+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "xHpWHQ2_A0f9"
   },
   "outputs": [],
   "source": [
    "# Feature Vector might have a NAN value therefore cionverting it to 0.0\n",
    "for num, sublist in enumerate(featureVec):\n",
    "    for i, value in enumerate(sublist):\n",
    "        if np.isnan(value):\n",
    "            featureVec[num][i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "niag1V6vZfjz"
   },
   "outputs": [],
   "source": [
    "#Loading and opredicting class of each mask based on its feature vector\n",
    "svmModel=joblib.load(\"svm_color_circu_stds_96.joblib\")\n",
    "labels=svmModel.predict(featureVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "id": "P7K1v6-WF2bO",
    "outputId": "9c05898b-4ef4-4e87-e262-245fa5d27130"
   },
   "outputs": [],
   "source": [
    "showClassDiffnew(mask_names,labels,[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGczpjxKMTUf",
    "outputId": "6daae63b-59a4-442a-f074-291dc01088d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 192\n",
      "1: 2\n",
      "2: 38\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(labels, return_counts=True)\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tOLIAaJiJnm3",
    "outputId": "6419282b-2cb5-46e2-958b-7aec7b5981e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actualClass={0:'cell',\n",
    "1:'bone',\n",
    "2:'fat',\n",
    "3:'bg'}\n",
    "for i,mask_name in enumerate(mask_names):\n",
    "  folder_name,file_name=mask_name.split('-')\n",
    "  image=cv2.imread(masks_directory+'/'+mask_name)\n",
    "  cv2.imwrite( output_directory_path+'/'+folder_name+'/'+actualClass[labels[i]]+'/'+file_name, image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dV64NH_ARK3"
   },
   "source": [
    "Now all the masks of each image are saved in each of their respective folder, we need to take a look at them to confirm that all masks are in their correct class, as they'll be converted to PascalVOC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dV64NH_ARK3"
   },
   "source": [
    "# Dataset making part 2 (To Pascal VOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dV64NH_ARK3"
   },
   "source": [
    "We use annotaion platform called CVAT to edit our annotations, This platform needs annotations in a standard format such as PascalVOC, COCO or Cityscapes. PascalVOC is a instance segmenataion annoatatation format, it is popular and easy to manipulate, as it saves annotations in form of images, rather than boundary pixel coordinate in XML files or JSON files used by COCO format.\n",
    "The following is the directory structure of PascalVOC:\n",
    "\n",
    "    Annotations\n",
    "        PGI_image_0.xml\n",
    "        PGI_image_1.xml\n",
    "    ImageSets\n",
    "        Main\n",
    "            default.txt\n",
    "        Segmentation\n",
    "            default.txt\n",
    "    JPEGImages (optional)\n",
    "        PGI_image_0.jpg\n",
    "        PGI_image_1.jpg        \n",
    "    SegmentationClass\n",
    "        PGI_image_0.jpg\n",
    "        PGI_image_1.jpg \n",
    "    SegmentationObject\n",
    "        PGI_image_0.png\n",
    "        PGI_image_1.png\n",
    "    lablmap.txt\n",
    "\n",
    "Explanation of each part:\n",
    "1. **Annotations:**     contains xml file that has basic information of each image i.e. filename, width, height\n",
    "2. **ImageSets:**     contains 2 txt files in Main and Segmentation, these files have only the name of each image\n",
    "3. **JPEGImages:**     a folder contating all the original images\n",
    "4. **SegmentationClass:**    a folder that contains a png file of the SegmenationClass image, In this image each pixel has the color of the class it belongs. for eg. all pixels that are cells will be coloured in a single color, in same fashion bg, bone and fat will also have a different color. So only 4 colors will be there in this image\n",
    "5. **SegmentationObject:**     a folder that contains a png file of the SegmentationObject image, In this image each object that was recogonized distinctly is given a different color, eg. fat1, fat2, bone1 and bone2 are different objects of the classes, all such objects are coloured differently. This image can contain 256 different colors (MAX LIMIT OF PascalVOC)\n",
    "6. **lablmap.txt:**     This file contains the color of each class in SegmentaionClass For eg. cell:128,0,0::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ZPSdkOFqEja6"
   },
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "msbZXsfNERJt"
   },
   "outputs": [],
   "source": [
    "#Making the Xml file like the following example:\n",
    "#     <annotation>\n",
    "#        <folder/>\n",
    "#            <filename>PGI_image_0.jpg</filename>\n",
    "#        <size>\n",
    "#            <width>1200</width>\n",
    "#            <height>1920</height>\n",
    "#            <depth/>\n",
    "#        </size>\n",
    "#        <segmented>1</segmented>\n",
    "#     </annotation>\n",
    "\n",
    "def makeXML(img, width, height):\n",
    "    annotation = etree.Element('annotation')\n",
    "\n",
    "    fo = etree.Element('folder')\n",
    "    fo.text =  ''\n",
    "\n",
    "    annotation.append(fo)\n",
    "\n",
    "    f = etree.Element('filename')\n",
    "    f.text = str(img+'.jpg')\n",
    "\n",
    "    annotation.append(f)\n",
    "\n",
    "    size = etree.Element('size')\n",
    "    w = etree.Element('width')\n",
    "    w.text = str(width)\n",
    "    h = etree.Element('height')\n",
    "    h.text = str(height)\n",
    "    d = etree.Element('depth')\n",
    "    d.text = str('')\n",
    "\n",
    "\n",
    "    size.append(w)\n",
    "    size.append(h)\n",
    "    size.append(d)\n",
    "    annotation.append(size)\n",
    "\n",
    "    segmented=etree.Element('segmented')\n",
    "    segmented.text='1'\n",
    "    annotation.append(segmented)\n",
    "\n",
    "\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QC-clTjJqju",
    "outputId": "e20beb80-9e30-4511-88da-0f1f8a2d09c0"
   },
   "outputs": [],
   "source": [
    "cleanOutput='./output126' # input the folder where we saved our annotations  \n",
    "OutputDir='PASCALoutput126/' # Folder that will contain the PascalVOC annotation\n",
    "imagesFolder='images126/' # Folder that will contains only images\n",
    "!mkdir $imagesFolder\n",
    "!mkdir $OutputDir\n",
    "!mkdir $OutputDir'SegmentationObject'\n",
    "!mkdir $OutputDir'SegmentationClass'\n",
    "!mkdir $OutputDir'Annotations'\n",
    "!mkdir $OutputDir'ImageSets'\n",
    "!mkdir $OutputDir'ImageSets/Main'\n",
    "!mkdir $OutputDir'ImageSets/Segmentation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "4UJYMAFMNn7k"
   },
   "outputs": [],
   "source": [
    "class_color={\n",
    "    'bone':[0,0,128],\n",
    "    'cell':[128,128,0],\n",
    "    'fat':[128,0,0],\n",
    "    'bg':[0,128,0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "J1j7UnV0JtHu"
   },
   "outputs": [],
   "source": [
    "default=\"\" #default.txt file in 'ImageSets/Main' and 'ImageSets/Segmentation'\n",
    "\n",
    "#EDIT THIS TO BE IN COORDINATION WITH class_color\n",
    "labelmap=\"# label:color_rgb:parts:actions\\nbackground:0,0,0::\\ncell:128,128,0::\\nfat:128,0,0::\\nbg:0,128,0::\\nbone:0,0,128::\" #labelmap.txt file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "qnSZLj7OPaNk"
   },
   "outputs": [],
   "source": [
    "# converting the saved image back to binary mask\n",
    "def binarize_for_pascal(rgb_image):\n",
    "    gray_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_mask = cv2.threshold(gray_image, 15, 255, cv2.THRESH_BINARY)\n",
    "    return binary_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "YQ4YF9BfFtWO"
   },
   "outputs": [],
   "source": [
    "#Function to get the 256 colors that are allowed in PascalVOC SegmentationObjects\n",
    "def color_map_get256(N=256):\n",
    "    def bitget(byteval, idx):\n",
    "        return ((byteval & (1 << idx)) != 0)\n",
    "\n",
    "    cmap = np.zeros((N, 3), dtype=np.dtype)\n",
    "    for i in range(N):\n",
    "        r = g = b = 0\n",
    "        c = i\n",
    "        for j in range(8):\n",
    "            r = r | (bitget(c, 0) << 7-j)\n",
    "            g = g | (bitget(c, 1) << 7-j)\n",
    "            b = b | (bitget(c, 2) << 7-j)\n",
    "            c = c >> 3\n",
    "\n",
    "        cmap[i] = np.array([r, g, b])\n",
    "    return cmap\n",
    "\n",
    "color_map256=color_map_get256()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "PXpH4US_K2Vb"
   },
   "outputs": [],
   "source": [
    "def addObject2Image(image,objects,color): # add an object to image with random color\n",
    "    masked_image=image.copy()\n",
    "    masked_image[objects==255]=color[::-1]\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "A71V09sXNY69"
   },
   "outputs": [],
   "source": [
    "def addClass2Image(image,mask,color_rgb):\n",
    "    color_bgr=color_rgb[::-1]\n",
    "    masked_image=image.copy()\n",
    "    masked_image[mask==255]=color_bgr\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWDi6MEDAQJP",
    "outputId": "e0e7afc6-6ec6-4f78-d5b0-497e72075021"
   },
   "outputs": [],
   "source": [
    "default=\"\" #making sure default file is empty before appending\n",
    "outofLimitMaskClasses=[]\n",
    "for n,dir in enumerate(os.listdir(cleanOutput)): #dir=MQ_image_0 or PGI_image_0\n",
    "        print(dir)\n",
    "        default+=dir+\"\\n\" #adding image name to default.txt\n",
    "\n",
    "        og_img=cv2.imread(cleanOutput+'/'+dir+'/og.tif')\n",
    "        cv2.imwrite(imagesFolder+dir+'.tif',og_img) #adding image to image directory for data to be uploaded later\n",
    "\n",
    "        #making annotation xml file for each image\n",
    "        og_image_shape=og_img.shape\n",
    "        annotation=makeXML(dir,og_image_shape[0],og_image_shape[1])\n",
    "        save_path = os.path.join(OutputDir+'Annotations/'+dir+ \".xml\")\n",
    "        with open(save_path, 'wb') as file:\n",
    "            aux = etree.tostring(annotation, pretty_print=True)\n",
    "            aux.decode(\"utf-8\")\n",
    "            file.write(aux)\n",
    "\n",
    "        image_objects=np.zeros(og_img.shape) #initiallly we use empty mask before overlaying individual masks on it\n",
    "        image_classes=np.zeros(og_img.shape) #initiallly we use empty mask before overlaying combined class mask on it\n",
    "        empty_mask=np.zeros_like(cv2.cvtColor(og_img,cv2.COLOR_BGR2GRAY)) #to save combined mask for each class\n",
    "\n",
    "        combined_class={\n",
    "            'bone': empty_mask,\n",
    "            'bg': empty_mask,\n",
    "            'fat': empty_mask,\n",
    "            'cell': empty_mask\n",
    "        }\n",
    "\n",
    "        color_number_for_mask=2 #start colouring masks from color no. 2 in color_map256\n",
    "\n",
    "        for item in os.listdir(cleanOutput+'/'+dir): # bone,cell,og.jpg\n",
    "            item_path = os.path.join(cleanOutput+'/'+dir, item) # '/Individual-Masks/MQ_image_0/bone'\n",
    "\n",
    "            if os.path.isdir(item_path) and  item!='cell': #open dirs other than cell and add their masks to combined_class and image_objects, SAM creates bad cell mask\n",
    "\n",
    "                masks = os.listdir(item_path)\n",
    "                if masks:\n",
    "                    for mask_name in masks: # mask= 10.jpg, 11.jpg\n",
    "                        # num_masks+=1\n",
    "                        mask=cv2.imread(item_path+'/'+mask_name)\n",
    "                        binary_mask=binarize_for_pascal(mask)\n",
    "\n",
    "                        combined_class[item]=cv2.bitwise_or(combined_class[item],binary_mask)  #combine each class's mask\n",
    "                        if len(masks)<200: # we want that each folder only have less than 200 masks then only we will allow it to add all its masks as different segmentation object, otherwise combine all the masks of that class together\n",
    "                            if color_number_for_mask<255: #255 first masks + 1 cell mask\n",
    "                                image_objects=addObject2Image(image_objects,binary_mask,color_map256[color_number_for_mask])\n",
    "                                color_number_for_mask+=1\n",
    "                            else:\n",
    "                                print(\"Individiual masks for \",dir,\" more than 256, combining those masks\") # CVAT and pascal VOC only allows 256 objects per image\n",
    "                        else:\n",
    "                            outofLimitMaskClasses.append(item)\n",
    "        for maskClass in outofLimitMaskClasses:\n",
    "            image_objects=addObject2Image(image_objects,combined_class[maskClass],class_color[maskClass])\n",
    "\n",
    "        removeable_area=cv2.bitwise_or(combined_class['bone'], combined_class['bg'])\n",
    "        removeable_area=cv2.bitwise_or(removeable_area, combined_class['fat'])\n",
    "        combined_class['cell']= remove_white_and_bone(og_img,removeable_area) # cell mask is generated from scratch by taking the non white part - bone part\n",
    "        image_objects=addObject2Image(image_objects,combined_class['cell'],color_map256[1])\n",
    "\n",
    "        for mask_class in ['cell','bg','fat','bone']:\n",
    "            image_classes=addClass2Image(image_classes,combined_class[mask_class],class_color[mask_class])\n",
    "        cv2.imwrite(OutputDir+'SegmentationObject/'+dir+'.png',image_objects)\n",
    "        cv2.imwrite(OutputDir+'SegmentationClass/'+dir+'.png',image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "H0WkiogUKHWw"
   },
   "outputs": [],
   "source": [
    "text_file = open(OutputDir+'ImageSets/Main/default.txt', \"w\")\n",
    "text_file.write(default)\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(OutputDir+'ImageSets/Segmentation/default.txt', \"w\")\n",
    "text_file.write(default)\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(OutputDir+'labelmap.txt', \"w\")\n",
    "text_file.write(labelmap)\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "OpaRfw4YlBsT",
    "1uLk_9aWI39_",
    "fM52mqQIk1Uj",
    "ZbFukmQGynmF"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
